output_dir = "./training_runs/qwen_lora_t2i"
dataset_config_path = "/root/wan2_2_lora/diffusion-pipe/configs/qwen_dataset.toml"
epochs = 100
micro_batch_size_per_gpu = 1
pipeline_stages = 1
gradient_accumulation_steps = 4
gradient_clipping = 1.0
warmup_steps = 100
blocks_to_swap = 32
save_every_n_epochs = 5
checkpoint_every_n_minutes = 120
activation_checkpointing = "unsloth"
save_dtype = "bfloat16"

[model]
type = "qwen_image"
diffusers_path = "/path/to/your/Qwen-Image"
transformer_path = "/path/to/your/qwen_image_edit_bf16.safetensors"
text_encoder_path = "/path/to/your/qwen_2.5_vl_7b.safetensors"
vae_path = "/path/to/your/Qwen-Image/vae/diffusion_pytorch_model.safetensors"
dtype = "bfloat16"
transformer_dtype = "float8"
timestep_sample_method = "logit_normal"

[adapter]
type = "lora"
rank = 32
dtype = "bfloat16"

[optimizer]
type = "AdamW8bitKahan"
lr = 5e-5
betas = [ 0.9, 0.99,]
weight_decay = 0.01
